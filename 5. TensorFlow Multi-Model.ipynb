{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import TensorFlowModel\n",
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker import get_execution_role\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import sagemaker\n",
    "import time\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version: 2.3.0\n",
      "Using SageMaker version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "print(f'Using TensorFlow version: {tf.__version__}')\n",
    "print(f'Using SageMaker version: {sagemaker.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "TF_FRAMEWORK_VERSION = '2.3.0'\n",
    "BUCKET = 'tf-mme-892313895307' # USE YOUR ACCOUNT ID OR INITIALS AS SUFFIX\n",
    "PREFIX = 'cv-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - CIFAR-10 Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Train & Validation Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: DATA/CIFAR_10/train/y_train.npy to s3://tf-mme-892313895307/cv-models/cifar/train/y_train.npy\n",
      "upload: DATA/CIFAR_10/train/X_train.npy to s3://tf-mme-892313895307/cv-models/cifar/train/X_train.npy\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./DATA/CIFAR_10/train s3://{BUCKET}/{PREFIX}/cifar/train --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: DATA/CIFAR_10/validation/y_validation.npy to s3://tf-mme-892313895307/cv-models/cifar/validation/y_validation.npy\n",
      "upload: DATA/CIFAR_10/validation/X_validation.npy to s3://tf-mme-892313895307/cv-models/cifar/validation/X_validation.npy\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./DATA/CIFAR_10/validation s3://{BUCKET}/{PREFIX}/cifar/validation --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: DATA/CIFAR_10/test/y_test.npy to s3://tf-mme-892313895307/cv-models/cifar/test/y_test.npy\n",
      "upload: DATA/CIFAR_10/test/X_test.npy to s3://tf-mme-892313895307/cv-models/cifar/test/X_test.npy\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./DATA/CIFAR_10/test s3://{BUCKET}/{PREFIX}/cifar/test --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar/train', \n",
    "                            distribution='FullyReplicated', \n",
    "                            content_type='npy')\n",
    "validation_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar/validation', \n",
    "                                 distribution='FullyReplicated', \n",
    "                                 content_type='npy')\n",
    "test_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar/test', \n",
    "                           distribution='FullyReplicated', \n",
    "                           content_type='npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'train': train_input, 'val': validation_input, 'test': test_input}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model-1'\n",
    "hyperparameters = {'epochs': 30}\n",
    "estimator_parameters = {'entry_point':'cifar_train.py',\n",
    "                        'instance_type': 'ml.m5.2xlarge',\n",
    "                        'instance_count': 1,\n",
    "                        'model_dir': f'/opt/ml/model',\n",
    "                        'role': role,\n",
    "                        'hyperparameters': hyperparameters,\n",
    "                        'output_path': f's3://{BUCKET}/{PREFIX}/cifar/out',\n",
    "                        'base_job_name': f'cv-{model_name}',\n",
    "                        'framework_version': TF_FRAMEWORK_VERSION,\n",
    "                        'py_version': 'py37',\n",
    "                        'script_mode': True}\n",
    "estimator_1 = TensorFlow(**estimator_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_1.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - Sign Language Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Train & Validation Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp ./DATA/SIGN_LANGUAGE/ s3://{BUCKET}/{PREFIX}/sign_lang --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/sign_lang/train', \n",
    "                            distribution='ShardedByS3Key')\n",
    "val_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/sign_lang/valid', \n",
    "                          distribution='ShardedByS3Key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model-2'\n",
    "\n",
    "hyperparameters = {'epochs': 20}\n",
    "estimator_parameters = {'entry_point':'sign_language_train.py',\n",
    "                        'instance_type': 'ml.m5.2xlarge',\n",
    "                        'instance_count': 1,\n",
    "                        'hyperparameters': hyperparameters,\n",
    "                        'model_dir': f'/opt/ml/model',\n",
    "                        'role': role,\n",
    "                        'output_path': f's3://{BUCKET}/{PREFIX}/sign_lang/out',\n",
    "                        'base_job_name': f'cv-{model_name}',\n",
    "                        'framework_version': TF_FRAMEWORK_VERSION,\n",
    "                        'py_version': 'py37',\n",
    "                        'script_mode': True}\n",
    "\n",
    "estimator_2 = TensorFlow(**estimator_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_2.fit({'train': train_input, 'val': val_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Model Endpoint (MME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_1 = estimator_1.model_data\n",
    "output_1 = f's3://{BUCKET}/{PREFIX}/mme/model-1.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_2 = estimator_2.model_data\n",
    "output_2 = f's3://{BUCKET}/{PREFIX}/mme/model-2.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://tf-mme-892313895307/cv-models/cifar/out/cv-model-1-2020-11-27-20-14-12-336/output/model.tar.gz to s3://tf-mme-892313895307/cv-models/mme/model-1.tar.gz\n",
      "copy: s3://tf-mme-892313895307/cv-models/sign_lang/out/cv-model-2-2020-11-27-20-44-45-298/output/model.tar.gz to s3://tf-mme-892313895307/cv-models/mme/model-2.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {tf_model_1} {output_1} \n",
    "!aws s3 cp {tf_model_2} {output_2} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy TensorFlow Model-1 as a Multi-Model Endpoint \n",
    "<p>https://github.com/aws/deep-learning-containers/blob/master/available_images.md</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-11-27-22-42-28'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_time = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d-%H-%M-%S')\n",
    "current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_URI = '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.1-cpu-py37-ubuntu18.04'\n",
    "model_data_prefix = f's3://{BUCKET}/{PREFIX}/mme/'\n",
    "model_1 = TensorFlowModel(model_data=output_1, \n",
    "                          role=role, \n",
    "                          image_uri=IMAGE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mme = MultiDataModel(name=f'mme-tensorflow-{current_time}',\n",
    "                     model_data_prefix=model_data_prefix,\n",
    "                     model=model_1,\n",
    "                     sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = mme.deploy(initial_instance_count=1,\n",
    "                       instance_type='ml.m5.2xlarge',\n",
    "                       endpoint_name=f'mme-tensorflow-{current_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-1.tar.gz', 'model-2.tar.gz']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mme.list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 373248 into shape (1,32,32,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a7910fd4c432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 373248 into shape (1,32,32,3)"
     ]
    }
   ],
   "source": [
    "img_path = './DATA/CIFAR_10/raw_images/truck.png'\n",
    "img = image.load_img(img_path)\n",
    "X = image.img_to_array(img)\n",
    "X = X.astype('float32')/255\n",
    "X = X.reshape(1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'instances': X}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(data=payload, initial_args={'TargetModel': 'model1.tar.gz'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './DATA/SIGN_LANGUAGE/test/0/IMG_1290.JPG'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "X = image.img_to_array(img)\n",
    "X = np.expand_dims(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'instances': X}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(data=payload, initial_args={'TargetModel': 'model2.tar.gz'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
